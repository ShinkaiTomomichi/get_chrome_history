{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_suggest\n",
    "\n",
    "* Chromeの履歴を元にオススメの動画一覧を取得します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pythonの基本ライブラリ\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ファイル操作\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Jupyter上にHTMLを表示する\n",
    "from IPython.display import HTML\n",
    "\n",
    "# 画像の保存\n",
    "import requests\n",
    "\n",
    "# YoutubeAPIの利用\n",
    "from apiclient.discovery import build\n",
    "from apiclient.errors import HttpError\n",
    "from oauth2client.client import flow_from_clientsecrets\n",
    "from oauth2client.tools import run_flow\n",
    "import google_auth_oauthlib.flow\n",
    "\n",
    "# 機械学習\n",
    "from transformers import BertJapaneseTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath = './output/viewed_videos.csv'\n",
    "df_viewed = pd.read_csv(outputPath)\n",
    "# df_viewed.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットから歌動画の抽出を行い推薦元データの作成\n",
    "\n",
    "# 適当に時間でフィルタリングして確認する\n",
    "filetered_df_viewed = df_viewed[np.logical_and(df_viewed['Duration']<480, df_viewed['Duration']>90)]\n",
    "print(\"再生時間によるフィルタリング後：\", filetered_df_viewed.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベリングように画像を作成\n",
    "# os.makedirs('./train/unlabeled/thumbnails/', exist_ok=True)\n",
    "# os.makedirs('./train/label_0/thumbnails/', exist_ok=True)\n",
    "# os.makedirs('./train/label_1/thumbnails/', exist_ok=True)\n",
    "\n",
    "# for i, row in filetered_df_viewed.iterrows():\n",
    "#     video_id, title, thumbnail = row['Id'], row['Title'], row['Thumbnail']\n",
    "    \n",
    "#     response = requests.get(thumbnail)\n",
    "#     image = response.content\n",
    "    \n",
    "#     title = title.replace('/', '')\n",
    "#     file_name = './train/unlabeled/thumbnails/'+title+'&separate&'+video_id+'.png'\n",
    "#     with open(file_name, \"wb\") as write_file:\n",
    "#         write_file.write(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベリングされた動画からテーブルを作成し直す\n",
    "video_ids = np.array(filetered_df_viewed['Id'])\n",
    "labels = np.zeros(video_ids.size, dtype=int)\n",
    "for label in range(2):\n",
    "    file_names = glob.glob('./train/thumbnails/label_'+str(label)+'/*')\n",
    "    for i, file_name in enumerate(file_names):\n",
    "        video_id = file_name.split('&separate&')[1].replace('.png', '')        \n",
    "        idx = np.where(video_ids == video_id)[0][0]\n",
    "        labels[idx] = label\n",
    "\n",
    "filetered_df_viewed['Label'] = labels\n",
    "\n",
    "filetered_df_viewed = filetered_df_viewed.reset_index()\n",
    "filetered_df_viewed = filetered_df_viewed.drop(['index'], axis=1)\n",
    "\n",
    "# Descriptionがnullのデータを補完\n",
    "filetered_df_viewed = filetered_df_viewed.fillna({'Description': 'Descriptionが記入されていません'})\n",
    "# filetered_df_viewed = filetered_df_viewed.replace({'Description': {'NULL': 'Descriptionが記入されていません'}})\n",
    "filetered_df_viewed.to_csv('./output/labeled_viewed_videos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viewed = pd.read_csv('./output/labeled_viewed_videos.csv')\n",
    "# df_viewed.isnull().sum() # 確認用\n",
    "# df_viewed.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トークナイザの準備\n",
    "MODEL_NAME = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained(MODEL_NAME)\n",
    "# print(bert_sc.config) # 語彙数が32000であることを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature(row, unique_channel_id, unique_category_id):\n",
    "    text = row['Title'] + row['Description']\n",
    "        \n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        max_length=max_length, \n",
    "        padding='max_length',\n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids']\n",
    "    input_ids = np.unique(input_ids) # countは一旦無視してuniqueにする\n",
    "    input_ids = input_ids[input_ids>=5] # [PAD], [UNK], [CLS], [SEP], [MASK]を削除\n",
    "    \n",
    "    words = np.zeros(32000)\n",
    "    words[input_ids] = 1\n",
    "    \n",
    "    channel_id = row['ChannelId']\n",
    "    if channel_id in unique_channel_id:\n",
    "        channel_onehot = np.eye(unique_channel_id.size)[unique_channel_id == channel_id][0]\n",
    "    else:\n",
    "        channel_onehot = np.zeros(unique_channel_id.size)\n",
    "    \n",
    "    category_id = row['CategoryId']\n",
    "    if category_id in unique_category_id:\n",
    "        category_onehot = np.eye(unique_category_id.size)[unique_category_id == category_id][0]\n",
    "    else:\n",
    "        category_onehot = np.zeros(unique_category_id.size)\n",
    "    \n",
    "    # scaleが違うので外しておく\n",
    "    # duration = row['Duration']\n",
    "    # view_count = row['ViewCount']\n",
    "    # like_count = row['LikeCount']\n",
    "    # comment_count = row['CommentCount']\n",
    "    # stats = np.array([duration, view_count, like_count, comment_count])\n",
    "    return np.concatenate([words, channel_onehot, category_onehot], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語分割して学習データを作成\n",
    "\n",
    "max_length = 512 # 最大で512\n",
    "X_train, Y_train = [], []\n",
    "unique_channel_id = np.unique(np.array(df_viewed['ChannelId']))\n",
    "unique_category_id = np.unique(np.array(df_viewed['CategoryId']))\n",
    "\n",
    "for i, row in df_viewed.iterrows():\n",
    "    X_row = make_feature(row, unique_channel_id, unique_category_id)\n",
    "    X_train.append(X_row)\n",
    "    Y_train.append(row['Label'])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "# 不要な特徴量を削除（計算量が重くなってきたら利用する）\n",
    "# no_use_idx = np.where(np.sum(X, axis=0) == 0)[0]\n",
    "# print(no_use_idx)\n",
    "# X = np.delete(X, no_use_idx, 1)\n",
    "\n",
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVで正解率を評価\n",
    "def cross_validation(X, Y, k=5):\n",
    "    # XとYをシャッフル\n",
    "    X, Y = shuffle(X, Y, random_state=0)\n",
    "    \n",
    "    # XとYをk分割\n",
    "    n = X.shape[0]\n",
    "    X_devs, Y_devs = [], []\n",
    "    for i in range(k):\n",
    "        if i != k-1:\n",
    "            X_dev, Y_dev = X[i*(n//5):(i+1)*(n//5)], Y[i*(n//5):(i+1)*(n//5)]\n",
    "        else:\n",
    "            X_dev, Y_dev = X[i*(n//5):], Y[i*(n//5):]\n",
    "        X_devs.append(X_dev)\n",
    "        Y_devs.append(Y_dev)\n",
    "        \n",
    "    # 1つをvalidation, 1つをテストとしてテスト誤差を計算する\n",
    "    test_accuracy = 0\n",
    "    for i in range(k):\n",
    "        print('k-cross-validation :', i+1, '/', k)\n",
    "        X_train_tmp, Y_train_tmp = [], []\n",
    "        for j in range(k-2):\n",
    "            X_train_tmp.append(X_devs[(i+j)%k])\n",
    "            Y_train_tmp.append(Y_devs[(i+j)%k])\n",
    "        X_train = np.concatenate(X_train_tmp)\n",
    "        Y_train = np.concatenate(Y_train_tmp)\n",
    "        X_val, Y_val = X_devs[(i+k-2)%k], Y_devs[(i+k-2)%k]\n",
    "        X_test, Y_test = X_devs[(i+k-1)%k], Y_devs[(i+k-1)%k]\n",
    "        \n",
    "        # logscaleでハイパラの候補を準備\n",
    "        lr = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "        lr.fit(X_train, Y_train)    \n",
    "        Y_pred = lr.predict(X_val)\n",
    "        test_accuracy_k = np.sum(Y_pred==Y_val)\n",
    "        test_accuracy += test_accuracy_k \n",
    "\n",
    "    return test_accuracy/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVを実施\n",
    "print('CV Accuracy', cross_validation(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Youtube APIの準備\n",
    "\n",
    "# APIキーをファイルから取得\n",
    "f = open('secret/apikey', 'r')\n",
    "api_key = f.read()\n",
    "f.close()\n",
    "\n",
    "# APIキーを用いてリクエスト用のクラスを作成\n",
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\"\n",
    "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 歌動画の関連動画の一覧を取得する\n",
    "df_viewed_song = df_viewed[df_viewed['Label'] == 1]\n",
    "video_ids = np.array(df_viewed_song['Id'])\n",
    "\n",
    "# 既に存在するIDの場合は省略する\n",
    "outputPath = './output/related_ids.csv'\n",
    "pred_df, prev_ids = None, []\n",
    "if os.path.exists(outputPath):\n",
    "    prev_df = pd.read_csv(outputPath)\n",
    "    prev_ids = np.array(prev_df['Id'])\n",
    "\n",
    "for video_id in video_ids:\n",
    "    if video_id not in prev_ids:\n",
    "        related_video_ids = []\n",
    "        try:\n",
    "            videos = youtube.search().list(\n",
    "                part = 'id', \n",
    "                relatedToVideoId = video_id,\n",
    "                order = 'relevance',\n",
    "                type = 'video',\n",
    "                maxResults = 50, \n",
    "            ).execute()\n",
    "        except HttpError as e:\n",
    "            print('データ参照中にエラーが発生しました')\n",
    "            print(e)\n",
    "            break\n",
    "    \n",
    "        # 既存のDataFrameに追加する形で用意する\n",
    "        for video_item in videos['items']:\n",
    "            related_video_ids.append(video_item['id']['videoId'])    \n",
    "        related_video_ids_str = ','.join(np.array(related_video_ids))\n",
    "        add_df = pd.DataFrame(data=np.array([video_id, related_video_ids_str]), \n",
    "                                            columns=['Id', 'RelatedVideoIds'])\n",
    "        if prev_df != None:\n",
    "            prev_df = pd.concat([prev_df, add_df])\n",
    "        else:\n",
    "            prev_df = add_df\n",
    "        \n",
    "        prev_df.to_csv(outputPath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サムネイルを表示する\n",
    "def output_html_related(base_ids, related_ids, top_n=10):    \n",
    "    html = '<h1>動画一覧を表示</h1>'\n",
    "    html += '<div style=\"float:left;\">'\n",
    "    for i, base_id in enumerate(base_ids):\n",
    "        html += ('<img src=\"http://img.youtube.com/vi/'+base_id+'/sddefault.jpg \"alt=\"取得できませんでした\" width=\"100\">')\n",
    "        html += ('<a href=\"https://www.youtube.com/watch?v='+base_id+'\">'+base_id+'</a><br>') \n",
    "        for related_id in related_ids[i][0:top_n]:\n",
    "            html += ('<img src=\"http://img.youtube.com/vi/'+related_id+'/sddefault.jpg \"alt=\"取得できませんでした\" width=\"50\">')\n",
    "            # html += ('<a href=\"https://www.youtube.com/watch?v='+related_url+'\">'+related_url+'</a><br>')\n",
    "        html += '<br>'\n",
    "    html += '</div>'\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関連動画がどのようなものか確認\n",
    "related_ids_df = pd.read_csv('./output/suggest_videos_tmp.csv')\n",
    "video_ids = np.array(related_ids_df['Id'])\n",
    "related_ids = np.array(related_ids_df['RelatedVideoIds'])\n",
    "related_ids_tmp1 = []\n",
    "for related_id1 in related_ids:\n",
    "    related_id_str = related_id1.split(',')\n",
    "    related_ids_tmp2 = []\n",
    "    for related_id2 in related_id_str:\n",
    "        related_ids_tmp2.append(related_id2)\n",
    "    related_ids_tmp1.append(related_ids_tmp2)\n",
    "\n",
    "# HTML(output_html_related(video_ids[0:5], related_ids_tmp1, top_n=18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サムネイルを表示する\n",
    "def output_html(video_ids, top_n=10):    \n",
    "    html = '<h1>動画一覧を表示</h1>'\n",
    "    html += '<div style=\"float:left;\">'\n",
    "    for video_id in video_ids[:top_n]:\n",
    "        html += ('<img src=\"http://img.youtube.com/vi/'+video_id+'/sddefault.jpg \"alt=\"取得できませんでした\" width=\"100\">')\n",
    "        html += ('<a href=\"https://www.youtube.com/watch?v='+video_id+'\">'+video_id+'</a><br>')\n",
    "    html += '</div>'\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_ids_df = pd.read_csv('./output/suggest_videos_tmp.csv')\n",
    "viewed_ids = np.array(related_ids_df['Id'])\n",
    "related_ids = np.array(related_ids_df['RelatedVideoIds'])\n",
    "\n",
    "related_ids_flat = []\n",
    "for related_id1 in related_ids:\n",
    "    related_id_str = related_id1.split(',')\n",
    "    for related_id2 in related_id_str:\n",
    "        related_ids_flat.append(related_id2)\n",
    "    \n",
    "related_ids_flat = np.array(related_ids_flat)\n",
    "unique_related_ids_flat, unique_related_ids_flat_counts = np.unique(related_ids_flat, return_counts=True)\n",
    "\n",
    "top_ids_argsort = np.argsort(unique_related_ids_flat_counts)[::-1]\n",
    "top_ids = unique_related_ids_flat[top_ids_argsort]\n",
    "# HTML(output_html(top_ids, top_n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISO表記の動画時間を秒に変換\n",
    "def pt2sec(pt_time):\n",
    "    s_list, m_list, h_list = [], [], []\n",
    "    conc_s, conc_m, conc_h = '', '', ''\n",
    "    flag = ''\n",
    "    \n",
    "    for i in reversed(pt_time):\n",
    "        if i == 'S':\n",
    "            flag = 'S'\n",
    "        elif i == 'M':\n",
    "            flag = 'M'\n",
    "        elif i == 'H':\n",
    "            flag = 'H'\n",
    "        elif i == 'T':\n",
    "            break\n",
    "        else:\n",
    "            if flag == 'S':\n",
    "                s_list.append(i)\n",
    "            elif flag == 'M':\n",
    "                m_list.append(i)\n",
    "            elif flag == 'H':\n",
    "                h_list.append(i)\n",
    "    \n",
    "    for s in reversed(s_list):\n",
    "        conc_s += s\n",
    "    for m in reversed(m_list):\n",
    "        conc_m += m\n",
    "    for h in reversed(h_list):\n",
    "        conc_h += h\n",
    "    conc_s = 0 if conc_s == '' else int(conc_s)\n",
    "    conc_m = 0 if conc_m == '' else int(conc_m)\n",
    "    conc_h = 0 if conc_h == '' else int(conc_h)\n",
    "\n",
    "    times = conc_h*3600 + conc_m*60 + conc_s\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関連動画のIDから詳細情報を取得する(5000件程度なら取得可能)\n",
    "video_details = []\n",
    "for i, video_id in enumerate(unique_related_ids_flat):\n",
    "    try:\n",
    "        video_detail = youtube.videos().list(\n",
    "            part = 'snippet,statistics,contentDetails', \n",
    "            id = video_id, \n",
    "        ).execute()\n",
    "    except HttpError as e:\n",
    "        print('エラーが発生しました')\n",
    "        # print(e)\n",
    "        break\n",
    "    \n",
    "    # 公開されていない動画など、取得できない場合がある\n",
    "    if len(video_detail['items']) == 0:\n",
    "        continue\n",
    "    video_snippet = video_detail['items'][0]['snippet']\n",
    "    video_statistics = video_detail['items'][0]['statistics']\n",
    "    video_content_details = video_detail['items'][0]['contentDetails']\n",
    "    # snippetから取得\n",
    "    date = video_snippet['publishedAt']\n",
    "    title = video_snippet['title']\n",
    "    channel_name = video_snippet['channelTitle']\n",
    "    channel_id = video_snippet['channelId']\n",
    "    description = video_snippet['description']\n",
    "    thumbnail = video_snippet['thumbnails']['high']['url']\n",
    "    category_id = video_snippet['categoryId']\n",
    "    # contentDetailsから取得\n",
    "    duration = pt2sec(video_content_details['duration'])\n",
    "    duration_origin = video_content_details['duration']\n",
    "    # statisticsから取得\n",
    "    # 評価数、コメントが非公開の場合は0で埋める\n",
    "    view_count = 0\n",
    "    like_count = 0\n",
    "    dislike_count = 0\n",
    "    comment_count = 0\n",
    "    if 'viewCount' in video_statistics.keys():\n",
    "        view_count = video_statistics['viewCount']\n",
    "    if 'likeCount' in video_statistics.keys():\n",
    "        like_count = video_statistics['likeCount']\n",
    "    if 'dislikeCount' in video_statistics.keys():\n",
    "        dislike_count = video_statistics['dislikeCount']\n",
    "    if 'commentCount' in video_statistics.keys():\n",
    "        comment_count = video_statistics['commentCount']\n",
    "    # 履歴情報を追加する\n",
    "    suggest_counts = unique_related_ids_flat_counts[i]\n",
    "    viewed = video_id in viewed_ids\n",
    "    \n",
    "    # リストのリストとして情報を格納する\n",
    "    video_details.append([video_id, channel_name, channel_id, date, title, \n",
    "                          thumbnail, category_id, duration, duration_origin, description, \n",
    "                          view_count, like_count, dislike_count, comment_count, \n",
    "                          suggest_counts, viewed])\n",
    "\n",
    "if len(video_details) != 0:\n",
    "    video_details_numpy = np.array(video_details)\n",
    "    video_details_pandas = pd.DataFrame(data=video_details_numpy, \n",
    "                                        columns=['Id', 'Name', 'ChannelId', 'Date', 'Title', \n",
    "                                                'Thumbnail', 'CategoryId', 'Duration', 'DurationOriginal', 'Description',\n",
    "                                                'ViewCount', 'LikeCount', 'DislikeCount', 'CommentCount', \n",
    "                                                'SuggestCount', 'Viewed'])\n",
    "\n",
    "    outputPath = './output/related_videos.csv'\n",
    "    video_details_pandas.to_csv(outputPath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LRを学習（アンバランスなのは一旦放置）\n",
    "related_videos_df = pd.read_csv(outputPath)\n",
    "X_test = []\n",
    "\n",
    "for i, row in related_videos_df.iterrows():\n",
    "    X_row = make_feature(row, unique_channel_id, unique_category_id)\n",
    "    X_test.append(X_row)\n",
    "    \n",
    "X_test = np.array(X_test)\n",
    "lr = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lr.fit(X_train, Y_train)\n",
    "Y_test = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_videos_df['Label'] = Y_test\n",
    "related_videos_df.to_csv(outputPath, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study-youtube",
   "language": "python",
   "name": "study-youtube"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
