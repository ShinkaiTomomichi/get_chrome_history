{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classify_related\n",
    "\n",
    "* 関連動画を歌動画とそうでないものに分類します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pythonの基本ライブラリ\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ファイル操作\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Jupyter上にHTMLを表示する\n",
    "from IPython.display import HTML\n",
    "\n",
    "# 画像の保存\n",
    "import requests\n",
    "\n",
    "# 機械学習\n",
    "from transformers import BertJapaneseTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "# LightGBMは精度の向上が見込め無さそうなので削除\n",
    "# import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータを取得\n",
    "month = '202208'\n",
    "input_path = './output/'+month+'/viewed_videos.csv'\n",
    "non_filtered_df_test = pd.read_csv(input_path)\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptionがnullのデータを補完\n",
    "non_filtered_df_test = non_filtered_df_test.fillna({'Description': 'Descriptionが記入されていません'})\n",
    "\n",
    "# 適当に時間でフィルタリングして確認する\n",
    "df_test = non_filtered_df_test[np.logical_and(non_filtered_df_test['Duration']<480, non_filtered_df_test['Duration']>90)]\n",
    "print(\"再生時間によるフィルタリング後：\", df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_channel_id = \n",
    "unique_category_id = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature(row, unique_channel_id, unique_category_id):\n",
    "    text = row['Title'] + row['Description']\n",
    "        \n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        max_length=max_length, \n",
    "        padding='max_length',\n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids']\n",
    "    input_ids = np.unique(input_ids) # countは一旦無視してuniqueにする\n",
    "    input_ids = input_ids[input_ids>=5] # [PAD], [UNK], [CLS], [SEP], [MASK]を削除\n",
    "    \n",
    "    words = np.zeros(32000)\n",
    "    words[input_ids] = 1\n",
    "    \n",
    "    channel_id = row['ChannelId']\n",
    "    if channel_id in unique_channel_id:\n",
    "        channel_onehot = np.eye(unique_channel_id.size)[unique_channel_id == channel_id][0]\n",
    "    else:\n",
    "        channel_onehot = np.zeros(unique_channel_id.size)\n",
    "    \n",
    "    category_id = row['CategoryId']\n",
    "    if category_id in unique_category_id:\n",
    "        category_onehot = np.eye(unique_category_id.size)[unique_category_id == category_id][0]\n",
    "    else:\n",
    "        category_onehot = np.zeros(unique_category_id.size)\n",
    "    \n",
    "    return np.concatenate([words, channel_onehot, category_onehot], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここで新規データの予測\n",
    "\n",
    "max_length = 512 # 最大で512\n",
    "X_test = []\n",
    "\n",
    "for i, row in df_test.iterrows():\n",
    "    X_row = make_feature(row, unique_channel_id, unique_category_id)\n",
    "    X_test.append(X_row)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Label'] = Y_test\n",
    "df_test.to_csv('./output/'+month+'/labeled_related_videos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サムネイルを表示する\n",
    "def output_html_labeled(video_ids, counts, labels, titles, top_n=10):    \n",
    "    html = '<h1>動画一覧を表示</h1>'\n",
    "    html += '<div style=\"float:left;\">'\n",
    "    for i, video_id in enumerate(video_ids[:top_n]):\n",
    "        html += ('<img src=\"http://img.youtube.com/vi/'+video_id+'/sddefault.jpg \"alt=\"取得できませんでした\" width=\"100\">')\n",
    "        html += ('<a href=\"https://www.youtube.com/watch?v='+video_id+'\">'+titles[i]+','+str(counts[i])+' ,'+str(labels[i])+'</a><br>')\n",
    "    html += '</div>'\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids = related_videos_df['Id']\n",
    "suggest_counts = related_videos_df['SuggestCount']\n",
    "labels = related_videos_df['Label']\n",
    "titles = related_videos_df['Title']\n",
    "\n",
    "# まずまずな感じなのであとはバリエーションをどうするかかね\n",
    "HTML(output_html_labeled(video_ids, suggest_counts, labels, titles, top_n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここは一旦保留か？\n",
    "\n",
    "# もう一度曲に対してVTuberかそうでないかを識別\n",
    "# 3000件の動画に対してラベリングを行い識別器を作る\n",
    "# これらは別のnotebookに分けてモデルだけ取得する形にした方が良いかも\n",
    "# これらのデータは次に使うデータとは別でtrainデータとして持ってくと良いかも\n",
    "\n",
    "outputPath = './output/related_videos.csv'\n",
    "related_videos_df = pd.read_csv(outputPath)\n",
    "X_test = []\n",
    "\n",
    "max_length = 512 # 最大で512\n",
    "X_train, Y_train = [], []\n",
    "unique_channel_id = np.unique(np.array(df_viewed['ChannelId']))\n",
    "unique_category_id = np.unique(np.array(df_viewed['CategoryId']))\n",
    "\n",
    "for i, row in df_viewed.iterrows():\n",
    "    X_row = make_feature(row, unique_channel_id, unique_category_id)\n",
    "    X_train.append(X_row)\n",
    "    Y_train.append(row['Label'])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "# 不要な特徴量を削除（計算量が重くなってきたら利用する）\n",
    "# no_use_idx = np.where(np.sum(X, axis=0) == 0)[0]\n",
    "# print(no_use_idx)\n",
    "# X = np.delete(X, no_use_idx, 1)\n",
    "\n",
    "Y_train = np.array(Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study-youtube",
   "language": "python",
   "name": "study-youtube"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
